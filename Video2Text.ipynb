{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NikhilTeja21/Video2Text-openai-whisper/blob/main/Video2Text.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VmQbdL78C6Pt"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
        "import moviepy.editor as mp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IDNXUctfDASi"
      },
      "outputs": [],
      "source": [
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1FFPz7MDAPf",
        "outputId": "3b4ba720-5699-4c22-bf24-5b10826f3dca"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "WhisperForConditionalGeneration(\n",
              "  (model): WhisperModel(\n",
              "    (encoder): WhisperEncoder(\n",
              "      (conv1): Conv1d(128, 1280, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "      (conv2): Conv1d(1280, 1280, kernel_size=(3,), stride=(2,), padding=(1,))\n",
              "      (embed_positions): Embedding(1500, 1280)\n",
              "      (layers): ModuleList(\n",
              "        (0-31): 32 x WhisperEncoderLayer(\n",
              "          (self_attn): WhisperSdpaAttention(\n",
              "            (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
              "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): GELUActivation()\n",
              "          (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "          (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (decoder): WhisperDecoder(\n",
              "      (embed_tokens): Embedding(51866, 1280, padding_idx=50256)\n",
              "      (embed_positions): WhisperPositionalEmbedding(448, 1280)\n",
              "      (layers): ModuleList(\n",
              "        (0-31): 32 x WhisperDecoderLayer(\n",
              "          (self_attn): WhisperSdpaAttention(\n",
              "            (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
              "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "          (activation_fn): GELUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): WhisperSdpaAttention(\n",
              "            (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
              "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "          (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "  )\n",
              "  (proj_out): Linear(in_features=1280, out_features=51866, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_id = \"openai/whisper-large-v3\"\n",
        "\n",
        "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
        "    model_id, low_cpu_mem_usage=True, use_safetensors=True\n",
        ")\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "SP5ChaxGDETT"
      },
      "outputs": [],
      "source": [
        "processor = AutoProcessor.from_pretrained(model_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "yizurXLLDD1i"
      },
      "outputs": [],
      "source": [
        "pipe = pipeline(\n",
        "    \"automatic-speech-recognition\",\n",
        "    model=model,\n",
        "    tokenizer=processor.tokenizer,\n",
        "    feature_extractor=processor.feature_extractor,\n",
        "    torch_dtype=torch_dtype,\n",
        "    device=device,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "G0dKDm8xDLfr",
        "outputId": "0318aa62-cba4-4780-fdeb-b108654ea927"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MoviePy - Writing audio in audio.mp3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                      "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MoviePy - Done.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r"
          ]
        }
      ],
      "source": [
        "video = mp.VideoFileClip(\"/content/vid1.mp4\")\n",
        "audio = video.audio\n",
        "audio.write_audiofile(\"audio.mp3\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ec5pDWMFCw_I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6253402-30e7-4663-8d29-a38936685b93"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
            "  warnings.warn(\n",
            "\n",
            "Due to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\n",
            "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.43.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n",
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " For our next story, let me ask you some questions. Have you ever tried booking a flight a day before? Or booking an Uber at peak traffic hour? Or even booking a hotel just hours ahead of check-in? If you have, then kudos to you. You went where others fear to tread. And that's because of exorbitant prices. Last-minute bookings cost a bomb. dynamic pricing. And what's that? Imagine you have a product, say a flight ticket. The airline is the seller, but it doesn't set a fixed price for the ticket. The price depends on the demand. If the demand is high, the price goes up. If the demand is low, if the flight is going empty, you can snag the ticket for cheap. It's a basic demand and supply principle. High demand, high prices. Low demand, low prices. And it is applicable for a range of things, like hotel rooms, ride-hailing apps, concert tickets, movie tickets, train anything and everything can be dynamically priced. But why is it done? Well, the United Kingdom, for one, is asking it. Last week, British band Ursus announced a reunion. The boy band will reunite next year. It is scheduled to play 17 shows. And tickets for those shows went on sale. One ticket was initially priced at £148. One ticket for £148. So fans joined the queue online to buy these tickets. But once they reached the checkout, they were in for a rude shock. The tickets had been rebranded. Why? Because of the growing demand. They were now selling for £355 a ticket. So more than 100% markup. And this hasn't gone down well with OSS fans, also with the British government, where Culture Secretary Lisa Nandy has slammed the inflated prices. The government is launching an investigation into the pricing of tickets. And this has triggered a debate on the practice of dynamic pricing. Is it good or bad? Is it fleecing people or just pure economics? Let's look at the pros first. Dynamic pricing focuses on one principle, the free market. Market forces determine the price of goods. If the demand is high, the charges are more. If it is lower, prices drop to attract more customers. It helps companies pad their margins, manage the inventory, and align better with the market. Take travel, for example. It's a volatile industry. So hotels and airlines must adjust prices to meet the demand. They can use dynamic pricing to optimize their revenue. But there's a catch. In concept, dynamic pricing works both ways, meaning prices can go higher or lower. But in practice, they seem to go only one way, and that is higher. Or we only notice when prices surge. For example, try booking a flight in off-season. Chances are the prices are lower than usual. But we take that as granted. Human psyche associates dynamic pricing to surge pricing only. And that puts off customers. Plus there's an agging question. Who determines this demand? What are the metrics used to measure it? Why is there no transparency in the process? and that is what makes customers doubt the process. They feel that the entire process is manipulative, that it's a scam to fleece them. Take Wendy's, for example. It recently introduced dynamic pricing. If there were more people in the store, they would pay more for a burger. That's what they introduced. But people were furious. They threatened to boycott the chain, so Wendy's took it back. Then there's PVRI Knox. They too have dynamic pricing for movie tickets. The idea is to increase footfall, But customers complain of high prices, which is why we need regulation. These are just two examples. A lot of companies do it. We need regulation because what if companies are increasing prices just for the sake of it? Say you order food. The company says the demand is high, so you pay for surge pricing. But where's the proof? How do you actually know that there is more traffic? Who regulates that? So we need mechanisms in place to monitor the extent and practice of dynamic pricing. So to sum it up, dynamic pricing can be a useful tool. On paper, it even sounds fair. But the problem is the way it's implemented. Customers always feel that they're losing out. What we need is more transparency from companies and a better understanding of how it works for customers. Tell us what you think. Thank you.\n"
          ]
        }
      ],
      "source": [
        "result = pipe(\"/content/audio.mp3\")\n",
        "print(result[\"text\"])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyNIzjrxYvXW5ZtNauNgODcy",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}